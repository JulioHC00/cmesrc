{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "import numpy as np\n",
    "import sqlite3\n",
    "\n",
    "from src.cmesrc.config import CMESRCV3_DB, GENERAL_DATASET, SDOML_DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "conn = sqlite3.connect(CMESRCV3_DB)\n",
    "cur = conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4098, 32684)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Starting point\n",
    "\n",
    "start_harpnums = cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM HARPS\").fetchone()[0]\n",
    "start_cmes = cur.execute(\"SELECT COUNT(*) FROM CMES\").fetchone()[0]\n",
    "\n",
    "start_harpnums, start_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4096, 32684)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pre-processign\n",
    "\n",
    "# Substep: Removing big harps\n",
    "\n",
    "big_harps_removed_harps = cur.execute(\"SELECT COUNT(*) FROM HARPS WHERE area < 18\").fetchone()[0]\n",
    "\n",
    "big_harps_removed_cmes = start_cmes # Unchanged\n",
    "\n",
    "big_harps_removed_harps, big_harps_removed_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 32684)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: Removing overlaps\n",
    "\n",
    "removed_overlaps_harps = cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM PROCESSED_HARPS_BBOX\").fetchone()[0]\n",
    "removed_overlaps_cmes = start_cmes # Unchanged\n",
    "\n",
    "removed_overlaps_harps, removed_overlaps_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 14507)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step: Associating CMEs to harps\n",
    "\n",
    "# Substep: Choose CMEs with happened during period HARPs exist\n",
    "\n",
    "cme_harps_harps = removed_overlaps_harps\n",
    "\n",
    "cme_harps_cmes = cur.execute(\"SELECT COUNT(*) FROM CMES WHERE cme_date BETWEEN (SELECT MIN(start) FROM HARPS) AND (SELECT MAX(END) FROM HARPS)\").fetchone()[0]\n",
    "\n",
    "cme_harps_harps, cme_harps_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 3755)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: CMEs with spatiotemporally matching regions\n",
    "\n",
    "cme_harps_matching_harps = cme_harps_harps\n",
    "\n",
    "cme_harps_matching_cmes = cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM CMES_HARPS_SPATIALLY_CONSIST\").fetchone()[0]\n",
    "\n",
    "cme_harps_matching_harps, cme_harps_matching_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 1001)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: Match using score criteria\n",
    "\n",
    "cme_harps_score_harps = cme_harps_matching_harps\n",
    "cme_harps_score_cmes = cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM FINAL_CME_HARP_ASSOCIATIONS\").fetchone()[0]\n",
    "\n",
    "cme_harps_score_harps, cme_harps_score_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step           | Substep                           |   CMEs |   SHARP regions |\n",
      "|:---------------|:----------------------------------|-------:|----------------:|\n",
      "| Starting point |                                   |  32684 |            4098 |\n",
      "| Pre-processing | Removing big harps                |  32684 |            4096 |\n",
      "| Pre-processing | Removing overlaps                 |  32684 |            3655 |\n",
      "| Matching       | CMEs during HARPs exist           |  14507 |            3655 |\n",
      "| Matching       | Spatiotemporally matching regions |   3755 |            3655 |\n",
      "| Matching       | Match criteria                    |   1001 |            3655 |\n"
     ]
    }
   ],
   "source": [
    "# Now put this in a nice table\n",
    "# with this columns\n",
    "# | Step | Substep | CMEs | SHARP regions |\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(columns=['Step', 'Substep', 'CMEs', 'SHARP regions'])\n",
    "\n",
    "df.loc[0] = ['Starting point', '', start_cmes, start_harpnums]\n",
    "df.loc[1] = ['Pre-processing', 'Removing big harps', big_harps_removed_cmes, big_harps_removed_harps]\n",
    "df.loc[2] = ['Pre-processing', 'Removing overlaps', removed_overlaps_cmes, removed_overlaps_harps]\n",
    "df.loc[3] = ['Matching', 'CMEs during HARPs exist', cme_harps_cmes, cme_harps_harps]\n",
    "df.loc[4] = ['Matching', 'Spatiotemporally matching regions', cme_harps_matching_cmes, cme_harps_matching_harps]\n",
    "df.loc[5] = ['Matching', 'Match criteria', cme_harps_score_cmes, cme_harps_score_harps]\n",
    "\n",
    "# Now print in markdown\n",
    "\n",
    "print(df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "gd_conn = sqlite3.connect(GENERAL_DATASET)\n",
    "gd_cur = gd_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3655, 1001)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now let's go to the general dataset\n",
    "\n",
    "# Step: Start\n",
    "\n",
    "start_harpnums = cme_harps_score_harps\n",
    "start_cmes = cme_harps_score_cmes\n",
    "\n",
    "start_harpnums, start_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3553, 1001)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step: Generating dataset\n",
    "\n",
    "# Substed: BBoxes within 70 degrees\n",
    "\n",
    "bboxes_70_harps = cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM PROCESSED_HARPS_BBOX WHERE LONDTMIN > -70 AND LONDTMAX < 70\").fetchone()[0]\n",
    "bboxes_70_cmes = start_cmes\n",
    "\n",
    "bboxes_70_harps, bboxes_70_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 498)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: Extract sequences\n",
    "\n",
    "sequences_harps = gd_cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM GENERAL_DATASET\").fetchone()[0]\n",
    "sequences_cmes = gd_cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM GENERAL_DATASET WHERE cme_id IS NOT NULL\").fetchone()[0]\n",
    "\n",
    "sequences_harps, sequences_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step               | Substep                  |   CMEs |   SHARP regions |\n",
      "|:-------------------|:-------------------------|-------:|----------------:|\n",
      "| Starting point     |                          |   1001 |            3655 |\n",
      "| Generating dataset | BBoxes within 70 degrees |   1001 |            3553 |\n",
      "| Generating dataset | Extract sequences        |    498 |            3551 |\n"
     ]
    }
   ],
   "source": [
    "# Same in nice table\n",
    "\n",
    "df = pd.DataFrame(columns=['Step', 'Substep', 'CMEs', 'SHARP regions'])\n",
    "\n",
    "df.loc[0] = ['Starting point', '', start_cmes, start_harpnums]\n",
    "df.loc[1] = ['Generating dataset', 'BBoxes within 70 degrees', bboxes_70_cmes, bboxes_70_harps]\n",
    "df.loc[2] = ['Generating dataset', 'Extract sequences', sequences_cmes, sequences_harps]\n",
    "\n",
    "# Now print in markdown\n",
    "\n",
    "print(df.to_markdown(index=False))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_conn = sqlite3.connect(SDOML_DATASET)\n",
    "sd_cur = sd_conn.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3551, 498)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_harpnums = sequences_harps\n",
    "start_cmes = sequences_cmes\n",
    "\n",
    "start_harpnums, start_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3548, 498)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step: Pre-processing\n",
    "\n",
    "# Substep: Need images and hourly\n",
    "\n",
    "# This isn't correct because HOURLY doesn't have the criteria for the sequences, in any case\n",
    "# 2692, 2699 and 2700 are gone because there aren't any images for a couple of days so well\n",
    "# 3230 just has 48 or 36 minute images (3 or 4 so no hourly)\n",
    "# 4345 has a single :48 image so gone too\n",
    "\n",
    "im_harps = sd_cur.execute(\"SELECT COUNT( DISTINCT harpnum) FROM HOURLY_PIXEL_BBOX\").fetchone()[0]\n",
    "im_cmes = sd_cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM GENERAL_DATASET WHERE cme_id IS NOT NULL AND harpnum IN (SELECT DISTINCT harpnum FROM HOURLY_PIXEL_BBOX)\").fetchone()[0]\n",
    "\n",
    "im_harps, im_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3416, 498)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: Removing overlaps\n",
    "\n",
    "sd_cur.executescript(\"\"\"\n",
    "CREATE TEMP TABLE IF NOT EXISTS ignore_harps AS\n",
    "    SELECT \n",
    "       CASE \n",
    "           WHEN harpnum_a_cme THEN harpnum_b \n",
    "           ELSE harpnum_a \n",
    "       END AS to_ignore \n",
    "FROM PIXEL_OVERLAPS\n",
    "WHERE harpnum_a_cme != harpnum_b_cme \n",
    "  AND mean_overlap > 30 \n",
    "  AND ocurrence_percentage > 30\n",
    "ORDER BY harpnum_a, harpnum_b ASC;\n",
    "\n",
    "CREATE TEMP TABLE IF NOT EXISTS no_overlap_harps AS\n",
    "    SELECT DISTINCT harpnum \n",
    "    FROM HOURLY_PIXEL_BBOX \n",
    "    WHERE harpnum NOT IN (SELECT to_ignore FROM ignore_harps);\n",
    "\"\"\")\n",
    "\n",
    "ov_harps = sd_cur.execute(\"SELECT COUNT(*) FROM no_overlap_harps\").fetchone()[0]\n",
    "ov_cmes = sd_cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM GENERAL_DATASET INNER JOIN no_overlap_harps ON GENERAL_DATASET.harpnum = no_overlap_harps.harpnum WHERE cme_id IS NOT NULL\").fetchone()[0]\n",
    "\n",
    "ov_harps, ov_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2137, 493)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Substep: Remove small harps\n",
    "\n",
    "sm_harps = sd_cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM ACCEPTED_HARPS\").fetchone()[0]\n",
    "sm_cmes = sd_cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM GENERAL_DATASET INNER JOIN ACCEPTED_HARPS AH ON GENERAL_DATASET.harpnum = AH.harpnum WHERE cme_id IS NOT NULL\").fetchone()[0]\n",
    "\n",
    "sm_harps, sm_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1914, 429)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step: Adjust General Dataset\n",
    "\n",
    "f_harps = sd_cur.execute(\"SELECT COUNT(DISTINCT harpnum) FROM SDOML_DATASET\").fetchone()[0]\n",
    "f_cmes = sd_cur.execute(\"SELECT COUNT(DISTINCT cme_id) FROM SDOML_DATASET WHERE cme_id IS NOT NULL\").fetchone()[0]\n",
    "\n",
    "f_harps, f_cmes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Step                   | Substep                |   CMEs |   SHARP regions |\n",
      "|:-----------------------|:-----------------------|-------:|----------------:|\n",
      "| Starting point         |                        |    498 |            3551 |\n",
      "| Pre-processing         | Need images and hourly |    498 |            3548 |\n",
      "| Pre-processing         | Removing overlaps      |    498 |            3416 |\n",
      "| Pre-processing         | Remove small harps     |    493 |            2137 |\n",
      "| Adjust General Dataset |                        |    429 |            1914 |\n"
     ]
    }
   ],
   "source": [
    "# Same in nice table\n",
    "\n",
    "df = pd.DataFrame(columns=['Step', 'Substep', 'CMEs', 'SHARP regions'])\n",
    "\n",
    "df.loc[0] = ['Starting point', '', start_cmes, start_harpnums]\n",
    "df.loc[1] = ['Pre-processing', 'Need images and hourly', im_cmes, im_harps]\n",
    "df.loc[2] = ['Pre-processing', 'Removing overlaps', ov_cmes, ov_harps]\n",
    "df.loc[3] = ['Pre-processing', 'Remove small harps', sm_cmes, sm_harps]\n",
    "df.loc[4] = ['Adjust General Dataset', '', f_cmes, f_harps]\n",
    "\n",
    "# Now print in markdown\n",
    "\n",
    "print(df.to_markdown(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slice_id</th>\n",
       "      <th>harpnum</th>\n",
       "      <th>lead_in_start</th>\n",
       "      <th>lead_in_end</th>\n",
       "      <th>obs_start</th>\n",
       "      <th>obs_end</th>\n",
       "      <th>pred_start</th>\n",
       "      <th>pred_end</th>\n",
       "      <th>prev_cme_id</th>\n",
       "      <th>prev_cme_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>pix_area</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_id</th>\n",
       "      <th>group_size</th>\n",
       "      <th>n_level_1</th>\n",
       "      <th>n_level_2</th>\n",
       "      <th>n_level_3</th>\n",
       "      <th>n_level_4</th>\n",
       "      <th>n_level_5</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>2010-05-02 08:30:00</td>\n",
       "      <td>2010-05-02 08:30:00</td>\n",
       "      <td>2010-05-03 08:30:00</td>\n",
       "      <td>2010-05-03 08:30:00</td>\n",
       "      <td>2010-05-11 16:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>2010-05-02 09:30:00</td>\n",
       "      <td>2010-05-02 09:30:00</td>\n",
       "      <td>2010-05-03 09:30:00</td>\n",
       "      <td>2010-05-03 09:30:00</td>\n",
       "      <td>2010-05-11 16:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>2010-05-02 10:30:00</td>\n",
       "      <td>2010-05-02 10:30:00</td>\n",
       "      <td>2010-05-03 10:30:00</td>\n",
       "      <td>2010-05-03 10:30:00</td>\n",
       "      <td>2010-05-11 16:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>2010-05-02 11:30:00</td>\n",
       "      <td>2010-05-02 11:30:00</td>\n",
       "      <td>2010-05-03 11:30:00</td>\n",
       "      <td>2010-05-03 11:30:00</td>\n",
       "      <td>2010-05-11 16:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-05-01 00:00:00</td>\n",
       "      <td>2010-05-02 12:30:00</td>\n",
       "      <td>2010-05-02 12:30:00</td>\n",
       "      <td>2010-05-03 12:30:00</td>\n",
       "      <td>2010-05-03 12:30:00</td>\n",
       "      <td>2010-05-11 16:12:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1711</td>\n",
       "      <td>908</td>\n",
       "      <td>908</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254171</th>\n",
       "      <td>373431</td>\n",
       "      <td>7331</td>\n",
       "      <td>2018-12-30 14:30:00</td>\n",
       "      <td>2019-01-03 06:30:00</td>\n",
       "      <td>2019-01-03 06:30:00</td>\n",
       "      <td>2019-01-04 06:30:00</td>\n",
       "      <td>2019-01-04 06:30:00</td>\n",
       "      <td>2019-01-07 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254172</th>\n",
       "      <td>373432</td>\n",
       "      <td>7331</td>\n",
       "      <td>2018-12-30 14:30:00</td>\n",
       "      <td>2019-01-03 07:30:00</td>\n",
       "      <td>2019-01-03 07:30:00</td>\n",
       "      <td>2019-01-04 07:30:00</td>\n",
       "      <td>2019-01-04 07:30:00</td>\n",
       "      <td>2019-01-07 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254173</th>\n",
       "      <td>373433</td>\n",
       "      <td>7331</td>\n",
       "      <td>2018-12-30 14:30:00</td>\n",
       "      <td>2019-01-03 08:30:00</td>\n",
       "      <td>2019-01-03 08:30:00</td>\n",
       "      <td>2019-01-04 08:30:00</td>\n",
       "      <td>2019-01-04 08:30:00</td>\n",
       "      <td>2019-01-07 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254174</th>\n",
       "      <td>373434</td>\n",
       "      <td>7331</td>\n",
       "      <td>2018-12-30 14:30:00</td>\n",
       "      <td>2019-01-03 09:30:00</td>\n",
       "      <td>2019-01-03 09:30:00</td>\n",
       "      <td>2019-01-04 09:30:00</td>\n",
       "      <td>2019-01-04 09:30:00</td>\n",
       "      <td>2019-01-07 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>254175</th>\n",
       "      <td>373435</td>\n",
       "      <td>7331</td>\n",
       "      <td>2018-12-30 14:30:00</td>\n",
       "      <td>2019-01-03 10:30:00</td>\n",
       "      <td>2019-01-03 10:30:00</td>\n",
       "      <td>2019-01-04 10:30:00</td>\n",
       "      <td>2019-01-04 10:30:00</td>\n",
       "      <td>2019-01-07 03:00:00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1225</td>\n",
       "      <td>1914</td>\n",
       "      <td>1914</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>254176 rows × 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        slice_id  harpnum        lead_in_start          lead_in_end  \\\n",
       "0              1        1  2010-05-01 00:00:00  2010-05-02 08:30:00   \n",
       "1              2        1  2010-05-01 00:00:00  2010-05-02 09:30:00   \n",
       "2              3        1  2010-05-01 00:00:00  2010-05-02 10:30:00   \n",
       "3              4        1  2010-05-01 00:00:00  2010-05-02 11:30:00   \n",
       "4              5        1  2010-05-01 00:00:00  2010-05-02 12:30:00   \n",
       "...          ...      ...                  ...                  ...   \n",
       "254171    373431     7331  2018-12-30 14:30:00  2019-01-03 06:30:00   \n",
       "254172    373432     7331  2018-12-30 14:30:00  2019-01-03 07:30:00   \n",
       "254173    373433     7331  2018-12-30 14:30:00  2019-01-03 08:30:00   \n",
       "254174    373434     7331  2018-12-30 14:30:00  2019-01-03 09:30:00   \n",
       "254175    373435     7331  2018-12-30 14:30:00  2019-01-03 10:30:00   \n",
       "\n",
       "                  obs_start              obs_end           pred_start  \\\n",
       "0       2010-05-02 08:30:00  2010-05-03 08:30:00  2010-05-03 08:30:00   \n",
       "1       2010-05-02 09:30:00  2010-05-03 09:30:00  2010-05-03 09:30:00   \n",
       "2       2010-05-02 10:30:00  2010-05-03 10:30:00  2010-05-03 10:30:00   \n",
       "3       2010-05-02 11:30:00  2010-05-03 11:30:00  2010-05-03 11:30:00   \n",
       "4       2010-05-02 12:30:00  2010-05-03 12:30:00  2010-05-03 12:30:00   \n",
       "...                     ...                  ...                  ...   \n",
       "254171  2019-01-03 06:30:00  2019-01-04 06:30:00  2019-01-04 06:30:00   \n",
       "254172  2019-01-03 07:30:00  2019-01-04 07:30:00  2019-01-04 07:30:00   \n",
       "254173  2019-01-03 08:30:00  2019-01-04 08:30:00  2019-01-04 08:30:00   \n",
       "254174  2019-01-03 09:30:00  2019-01-04 09:30:00  2019-01-04 09:30:00   \n",
       "254175  2019-01-03 10:30:00  2019-01-04 10:30:00  2019-01-04 10:30:00   \n",
       "\n",
       "                   pred_end  prev_cme_id  prev_cme_diff  ...  pix_area  \\\n",
       "0       2010-05-11 16:12:00          NaN            NaN  ...      1711   \n",
       "1       2010-05-11 16:12:00          NaN            NaN  ...      1711   \n",
       "2       2010-05-11 16:12:00          NaN            NaN  ...      1711   \n",
       "3       2010-05-11 16:12:00          NaN            NaN  ...      1711   \n",
       "4       2010-05-11 16:12:00          NaN            NaN  ...      1711   \n",
       "...                     ...          ...            ...  ...       ...   \n",
       "254171  2019-01-07 03:00:00          NaN            NaN  ...      1225   \n",
       "254172  2019-01-07 03:00:00          NaN            NaN  ...      1225   \n",
       "254173  2019-01-07 03:00:00          NaN            NaN  ...      1225   \n",
       "254174  2019-01-07 03:00:00          NaN            NaN  ...      1225   \n",
       "254175  2019-01-07 03:00:00          NaN            NaN  ...      1225   \n",
       "\n",
       "        group_id  group_id  group_size  n_level_1  n_level_2  n_level_3  \\\n",
       "0            908       908           1          0          0          0   \n",
       "1            908       908           1          0          0          0   \n",
       "2            908       908           1          0          0          0   \n",
       "3            908       908           1          0          0          0   \n",
       "4            908       908           1          0          0          0   \n",
       "...          ...       ...         ...        ...        ...        ...   \n",
       "254171      1914      1914           1          0          0          0   \n",
       "254172      1914      1914           1          0          0          0   \n",
       "254173      1914      1914           1          0          0          0   \n",
       "254174      1914      1914           1          0          0          0   \n",
       "254175      1914      1914           1          0          0          0   \n",
       "\n",
       "        n_level_4  n_level_5  split  \n",
       "0               0          0      4  \n",
       "1               0          0      4  \n",
       "2               0          0      4  \n",
       "3               0          0      4  \n",
       "4               0          0      4  \n",
       "...           ...        ...    ...  \n",
       "254171          0          0      4  \n",
       "254172          0          0      4  \n",
       "254173          0          0      4  \n",
       "254174          0          0      4  \n",
       "254175          0          0      4  \n",
       "\n",
       "[254176 rows x 43 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now I just want a better description of the splits so let's gather some data\n",
    "\n",
    "df = pd.read_sql(\"\"\"\n",
    "SELECT * FROM SDOML_DATASET\n",
    "INNER JOIN SDOML_HARPS ON SDOML_DATASET.harpnum = SDOML_HARPS.harpnum\n",
    "INNER JOIN SDOML_GROUPS ON SDOML_HARPS.group_id = SDOML_GROUPS.group_id\n",
    "\"\"\", sd_conn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   split |     0 |    1 |\n",
      "|--------:|------:|-----:|\n",
      "|       1 | 44147 | 5780 |\n",
      "|       2 | 46611 | 6200 |\n",
      "|       3 | 45154 | 6057 |\n",
      "|       4 | 42944 | 6083 |\n",
      "|       5 | 45164 | 6036 |\n"
     ]
    }
   ],
   "source": [
    "# Now, I want to know the number of positive and negative rows (label) per split\n",
    "\n",
    "nrows = df.groupby(['split', 'label']).size().reset_index(name='counts')\n",
    "\n",
    "n_rows_pivot = pd.pivot_table(nrows, values='counts', index=['split'], columns=['label'], aggfunc=np.sum)\n",
    "\n",
    "# Print in markdown\n",
    "\n",
    "print(n_rows_pivot.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   split |   1.0 |   2.0 |   3.0 |   4.0 |   5.0 |\n",
      "|--------:|------:|------:|------:|------:|------:|\n",
      "|       1 |     7 |     6 |    10 |    37 |    28 |\n",
      "|       2 |     7 |     6 |    10 |    36 |    28 |\n",
      "|       3 |     7 |     6 |     9 |    36 |    28 |\n",
      "|       4 |     6 |     6 |     9 |    36 |    28 |\n",
      "|       5 |     6 |     5 |     9 |    36 |    27 |\n"
     ]
    }
   ],
   "source": [
    "# Now the number of CMEs per split by verification level\n",
    "\n",
    "ncmes = df[df[\"label\"].astype(bool)].drop_duplicates(subset=['cme_id']).groupby(['split', 'verification_level']).size().reset_index(name='counts')\n",
    "\n",
    "ncmes_pivot = pd.pivot_table(ncmes, values='counts', index=['split'], columns=['verification_level'], aggfunc=np.sum)\n",
    "\n",
    "# To markdown\n",
    "\n",
    "print(ncmes_pivot.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   split |   0 |   1 |\n",
      "|--------:|----:|----:|\n",
      "|       1 | 311 |  72 |\n",
      "|       2 | 315 |  68 |\n",
      "|       3 | 315 |  68 |\n",
      "|       4 | 317 |  66 |\n",
      "|       5 | 318 |  64 |\n"
     ]
    }
   ],
   "source": [
    "# Now number of cme productive and non cme productive regions per split\n",
    "\n",
    "nreg = df.sort_values(by=\"label\", ascending=False).drop_duplicates(subset=['harpnum'], keep=\"first\").groupby(['split', 'label']).size().reset_index(name='counts')\n",
    "\n",
    "nreg_pivot = pd.pivot_table(nreg, values='counts', index=['split'], columns=['label'], aggfunc=np.sum)\n",
    "\n",
    "# To markdown\n",
    "\n",
    "print(nreg_pivot.to_markdown())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
